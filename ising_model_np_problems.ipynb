{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# conda environments:\n",
      "#\n",
      "base                     /opt/conda\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def from_torch_to_numpy(tensor: torch.Tensor):\n",
    "    return tensor.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def energy_function(p_bits: torch.Tensor, weights: torch.Tensor, bias: torch.Tensor):\n",
    "    return np.sum(np.multiply(from_torch_to_numpy(weights), from_torch_to_numpy(torch.outer(p_bits, p_bits)))) + torch.dot(p_bits, bias)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gradient(p_bits: torch.Tensor, weights: torch.Tensor, bias: torch.Tensor):\n",
    "    energy = energy_function(p_bits, weights, bias) \n",
    "    energy.backward(torch.ones(energy.shape))\n",
    "    p_bits.retain_grad()\n",
    "    return p_bits.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation_function(syn_input: torch.Tensor, beta: float):\n",
    "    return torch.sign(torch.tanh(beta * (-syn_input)) - (torch.rand(1) * 2 - 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_energy_minimum(initial_beta, weights: torch.Tensor, bias: torch.Tensor, n: int):\n",
    "    p_bits = torch.ones(n, requires_grad=True)\n",
    "    prev_energy = energy_function(p_bits, weights, bias)\n",
    "    beta = initial_beta\n",
    "    ans = torch.ones(n, requires_grad=True) \n",
    "    last_change_index = 0\n",
    "    for i in range(100):\n",
    "        indices = torch.randperm(n)\n",
    "        for index, value in enumerate(indices):\n",
    "            new_beta = beta + 0.1\n",
    "            iteration = n * i + index\n",
    "            gradient = calculate_gradient(p_bits, weights, bias)\n",
    "            syn_input = gradient[value]\n",
    "            old_value = p_bits[value].item()\n",
    "            with torch.no_grad():\n",
    "                p_bits[value] = activation_function(syn_input, new_beta)\n",
    "            new_energy = energy_function(p_bits, weights, bias)\n",
    "            \n",
    "            if torch.abs(new_energy) < torch.abs(prev_energy): \n",
    "                beta = new_beta\n",
    "                prev_energy = new_energy\n",
    "                ans = p_bits.clone()\n",
    "    return ans.tolist()\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Number partitioning task**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First set of numbers: \n",
      "1 3 4 6 8 9 11 14 17 19 20 23 26 28 29 30\n",
      "Second set of numbers: \n",
      "2 5 7 10 12 13 15 16 18 21 22 24 25 27 31\n"
     ]
    }
   ],
   "source": [
    "numbers = range(1, 32)\n",
    "n = len(numbers)\n",
    "weights = torch.zeros((n, n), dtype=torch.float32)\n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        weights[i][j] = numbers[i] * numbers[j] \n",
    "bias = torch.zeros(n, dtype=torch.float32)\n",
    "\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "result = find_energy_minimum(0.5, weights, bias, n)\n",
    "\n",
    "if torch.dot(torch.tensor(numbers, dtype=torch.float32), torch.tensor(result)) != 0:\n",
    "    print(\"The partitioning of this numbers is impossible\")\n",
    "else:\n",
    "    print(\"First set of numbers: \")\n",
    "    first_set_of_numbers = []\n",
    "    second_set_of_numbers = []\n",
    "    for index, el in enumerate(result):\n",
    "        if el == 1.0:\n",
    "            first_set_of_numbers.append(int(el * numbers[index]))\n",
    "        else:\n",
    "            second_set_of_numbers.append(int(-el * numbers[index]))    \n",
    "    print(*first_set_of_numbers)\n",
    "    print(\"Second set of numbers: \")\n",
    "    print(*second_set_of_numbers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Graph partitioning task**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First set of vertices: \n",
      "0 1 2 3\n",
      "Second set of vertices: \n",
      "4 5 6 7\n"
     ]
    }
   ],
   "source": [
    "n = 8\n",
    "pairs = {1: [2, 3, 0], 2: [1, 3, 0], 3: [1, 2, 0], 0: [1, 2, 3], 5: [4, 6, 7]\n",
    ", 6: [4, 5, 7], 7: [4, 5, 6], 4: [5, 6, 7]}\n",
    "# n = 6\n",
    "# pairs = {1: [2, 0], 2: [1, 0], 0: [2, 1], 3: [4, 5], 4: [5, 3]\n",
    "# , 5: [4, 3]}\n",
    "# n = 4\n",
    "# pairs = {1: [2, 3], 2: [1], 3: [1, 0], 0: [3]}\n",
    "\n",
    "weights = torch.zeros((n, n), dtype=torch.float32)\n",
    "free_term = 0 \n",
    "for i in range(n):\n",
    "    for j in range(n):\n",
    "        if j in pairs[i]:\n",
    "            weights[i][j] -= 1 / 2\n",
    "            free_term += 1 / 2\n",
    "        weights[i][j] += 1\n",
    "weights[0][0] += free_term\n",
    "\n",
    "bias = torch.zeros(n, dtype=torch.float32)\n",
    "seed = 42\n",
    "torch.manual_seed(seed)\n",
    "result = find_energy_minimum(0.5, weights, bias, n)\n",
    "\n",
    "first_set_of_vertices = []\n",
    "second_set_of_vertices = []\n",
    "for index, el in enumerate(result):\n",
    "    if el == 1.0:\n",
    "        first_set_of_vertices.append(int(el * numbers[index]) - 1)\n",
    "    else:\n",
    "        second_set_of_vertices.append(int(-el * numbers[index]) - 1)    \n",
    "\n",
    "print(\"First set of vertices: \")\n",
    "print(*first_set_of_vertices)\n",
    "print(\"Second set of vertices: \")\n",
    "print(*second_set_of_vertices)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computation time difference for Number Paritioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def complete_search(numbers):\n",
    "    total_sum = sum(numbers)\n",
    "    num_elements = len(numbers)\n",
    "    \n",
    "    best_partition = None\n",
    "    min_partition_diff = float('inf')\n",
    "    for i in range(1, num_elements // 2 + 1):\n",
    "        for subset in itertools.combinations(numbers, i):\n",
    "            subset_sum = sum(subset)\n",
    "            complement_sum = total_sum - subset_sum\n",
    "            partition_diff = abs(subset_sum - complement_sum)\n",
    "            \n",
    "            if partition_diff < min_partition_diff:\n",
    "                min_partition_diff = partition_diff\n",
    "                best_partition = (list(subset), [x for x in numbers if x not in subset])\n",
    "    \n",
    "    return best_partition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases = [30, 31]\n",
    "\n",
    "execution_times_find_energy_minimum = []\n",
    "execution_times_complete_search = []\n",
    "\n",
    "\n",
    "for test in test_cases:\n",
    "    numbers = range(1, test + 1)\n",
    "    complete_search_time_start = time.time()\n",
    "    complete_search(numbers)\n",
    "    complete_search_time_end = time.time()\n",
    "    execution_times_complete_search.append(complete_search_time_end - complete_search_time_start)\n",
    "    find_energy_minimum_time_start = time.time()\n",
    "    n = len(numbers)\n",
    "    weights = torch.zeros((n, n), dtype=torch.float32)\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            weights[i][j] = numbers[i] * numbers[j] \n",
    "    bias = torch.zeros(n, dtype=torch.float32)\n",
    "\n",
    "    result = find_energy_minimum(0.5, weights, bias, n)\n",
    "    find_energy_minimum_time_end = time.time()\n",
    "    execution_times_find_energy_minimum.append(find_energy_minimum_time_end - find_energy_minimum_time_start)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[166.19825863838196, 294.98395586013794]\n",
      "[1.0487761497497559, 1.011204719543457]\n"
     ]
    }
   ],
   "source": [
    "print(execution_times_complete_search)\n",
    "print(execution_times_find_energy_minimum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-7a0bfcb5010e4820bd3b59ab2498e6d2.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-7a0bfcb5010e4820bd3b59ab2498e6d2.vega-embed details,\n",
       "  #altair-viz-7a0bfcb5010e4820bd3b59ab2498e6d2.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-7a0bfcb5010e4820bd3b59ab2498e6d2\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-7a0bfcb5010e4820bd3b59ab2498e6d2\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-7a0bfcb5010e4820bd3b59ab2498e6d2\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.15.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.15.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"layer\": [{\"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"value\": \"blue\"}, \"tooltip\": [{\"field\": \"Input Cases\", \"type\": \"quantitative\"}, {\"field\": \"Complete Search Execution Time\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Input Cases\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"Complete Search Execution Time\", \"type\": \"quantitative\"}}, \"name\": \"view_2\", \"title\": \"Computational Difference Between Complete Search and Our Approach\"}, {\"mark\": {\"type\": \"line\", \"point\": true}, \"encoding\": {\"color\": {\"value\": \"red\"}, \"tooltip\": [{\"field\": \"Input Cases\", \"type\": \"quantitative\"}, {\"field\": \"Our Approach Execution Time\", \"type\": \"quantitative\"}], \"x\": {\"field\": \"Input Cases\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"Our Approach Execution Time\", \"type\": \"quantitative\"}}}], \"data\": {\"name\": \"data-5d71a382264e8ec503712f7cd123fe2f\"}, \"params\": [{\"name\": \"param_2\", \"select\": {\"type\": \"interval\", \"encodings\": [\"x\", \"y\"]}, \"bind\": \"scales\", \"views\": [\"view_2\"]}], \"width\": 500, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.15.1.json\", \"datasets\": {\"data-5d71a382264e8ec503712f7cd123fe2f\": [{\"Input Cases\": 6, \"Complete Search Execution Time\": 5.7697296142578125e-05, \"Our Approach Execution Time\": 0.18785452842712402}, {\"Input Cases\": 8, \"Complete Search Execution Time\": 7.700920104980469e-05, \"Our Approach Execution Time\": 0.22379279136657715}, {\"Input Cases\": 12, \"Complete Search Execution Time\": 0.0006759166717529297, \"Our Approach Execution Time\": 0.34358716011047363}, {\"Input Cases\": 18, \"Complete Search Execution Time\": 0.03530168533325195, \"Our Approach Execution Time\": 0.5495147705078125}, {\"Input Cases\": 19, \"Complete Search Execution Time\": 0.05919766426086426, \"Our Approach Execution Time\": 0.5546219348907471}, {\"Input Cases\": 20, \"Complete Search Execution Time\": 0.2158496379852295, \"Our Approach Execution Time\": 0.5766348838806152}, {\"Input Cases\": 21, \"Complete Search Execution Time\": 0.24437642097473145, \"Our Approach Execution Time\": 0.7116522789001465}, {\"Input Cases\": 22, \"Complete Search Execution Time\": 0.5796020030975342, \"Our Approach Execution Time\": 0.7572066783905029}, {\"Input Cases\": 23, \"Complete Search Execution Time\": 1.0086231231689453, \"Our Approach Execution Time\": 0.6926448345184326}, {\"Input Cases\": 27, \"Complete Search Execution Time\": 16.80867075920105, \"Our Approach Execution Time\": 0.9135968685150146}, {\"Input Cases\": 28, \"Complete Search Execution Time\": 39.62793040275574, \"Our Approach Execution Time\": 0.964179277420044}, {\"Input Cases\": 29, \"Complete Search Execution Time\": 69.11628222465515, \"Our Approach Execution Time\": 0.9963042736053467}, {\"Input Cases\": 32, \"Complete Search Execution Time\": 665.634993314743, \"Our Approach Execution Time\": 1.041233777999878}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.LayerChart(...)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import altair as alt\n",
    "\n",
    "data = pd.DataFrame({\n",
    "    'Input Cases': test_cases,\n",
    "    'Complete Search Execution Time': execution_times_complete_search,\n",
    "    'Our Approach Execution Time': execution_times_find_energy_minimum\n",
    "})\n",
    "\n",
    "chart = alt.Chart(data).mark_line(point=True).encode(\n",
    "    x='Input Cases',\n",
    "    y='Complete Search Execution Time:Q',\n",
    "    color=alt.value('blue'),\n",
    "    tooltip=['Input Cases', 'Complete Search Execution Time']\n",
    ").properties(\n",
    "    title='Computational Difference Between Complete Search and Our Approach',\n",
    "    width=500\n",
    ") + alt.Chart(data).mark_line(point=True).encode(\n",
    "    x='Input Cases',\n",
    "    y='Our Approach Execution Time',\n",
    "    color=alt.value('red'),\n",
    "    tooltip=['Input Cases', 'Our Approach Execution Time']\n",
    ")\n",
    "\n",
    "chart.interactive()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
